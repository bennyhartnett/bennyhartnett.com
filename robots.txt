# Robots.txt for bennyhartnett.com
# Enterprise SEO Configuration

User-agent: *
Allow: /
Disallow: /assets/d/
Disallow: /download

# Subdomain architecture - All content pages served via subdomains
# https://bennyhartnett.com (main domain - homepage)
# https://generative-ai.bennyhartnett.com (AI content)
# https://nuclear.bennyhartnett.com (Nuclear calculator & research)
# https://government-contracting.bennyhartnett.com (GovCon insights)
# https://projects.bennyhartnett.com (Portfolio)
# https://contact.bennyhartnett.com (Contact form)
# https://chat.bennyhartnett.com (AI chat)
# https://privacy.bennyhartnett.com (Privacy policy)
# https://github.bennyhartnett.com (GitHub profile redirect)
# https://linkedin.bennyhartnett.com (LinkedIn profile redirect)

# AI/LLM Crawlers - Welcome!
# For AI assistants and LLM crawlers, see our dedicated files:
# https://bennyhartnett.com/llms.txt (summary)
# https://bennyhartnett.com/llms-full.txt (detailed)

User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: Anthropic-AI
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: Cohere-AI
Allow: /

User-agent: Meta-ExternalAgent
Allow: /

User-agent: Meta-ExternalFetcher
Allow: /

User-agent: Bytespider
Allow: /

User-agent: CCBot
Allow: /

User-agent: Omgilibot
Allow: /

User-agent: Diffbot
Allow: /

User-agent: YouBot
Allow: /

User-agent: Applebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Googlebot
Allow: /

# Sitemap location
Sitemap: https://bennyhartnett.com/sitemap.xml

# Crawl-delay for polite crawling (optional, respected by some bots)
# Crawl-delay: 1
